import"clsx";import{b as ee}from"./server.js";import"@sveltejs/kit/internal/server";const A={apiKey:"",systemMessage:"",theme:"system",showTokensPerSecond:!1,showThoughtInProgress:!1,disableReasoningFormat:!1,keepStatsVisible:!1,showMessageStats:!0,askForTitleConfirmation:!1,pasteLongTextToFileLen:2500,pdfAsImage:!1,showModelInfo:!1,renderUserContentAsMarkdown:!1,modelSelectorEnabled:!1,samplers:"top_k;typ_p;top_p;min_p;temperature",temperature:.8,dynatemp_range:0,dynatemp_exponent:1,top_k:40,top_p:.95,min_p:.05,xtc_probability:0,xtc_threshold:.1,typ_p:1,repeat_last_n:64,repeat_penalty:1,presence_penalty:0,frequency_penalty:0,dry_multiplier:0,dry_base:1.75,dry_allowed_length:2,dry_penalty_last_n:-1,max_tokens:-1,custom:"",pyInterpreterEnabled:!1},me={apiKey:"Set the API Key if you are using --api-key option for the server.",systemMessage:"The starting message that defines how model should behave.",theme:"Choose the color theme for the interface. You can choose between System (follows your device settings), Light, or Dark.",pasteLongTextToFileLen:"On pasting long text, it will be converted to a file. You can control the file length by setting the value of this parameter. Value 0 means disable.",samplers:'The order at which samplers are applied, in simplified way. Default is "top_k;typ_p;top_p;min_p;temperature": top_k->typ_p->top_p->min_p->temperature',temperature:"Controls the randomness of the generated text by affecting the probability distribution of the output tokens. Higher = more random, lower = more focused.",dynatemp_range:"Addon for the temperature sampler. The added value to the range of dynamic temperature, which adjusts probabilities by entropy of tokens.",dynatemp_exponent:"Addon for the temperature sampler. Smoothes out the probability redistribution based on the most probable token.",top_k:"Keeps only k top tokens.",top_p:"Limits tokens to those that together have a cumulative probability of at least p",min_p:"Limits tokens based on the minimum probability for a token to be considered, relative to the probability of the most likely token.",xtc_probability:"XTC sampler cuts out top tokens; this parameter controls the chance of cutting tokens at all. 0 disables XTC.",xtc_threshold:"XTC sampler cuts out top tokens; this parameter controls the token probability that is required to cut that token.",typ_p:"Sorts and limits tokens based on the difference between log-probability and entropy.",repeat_last_n:"Last n tokens to consider for penalizing repetition",repeat_penalty:"Controls the repetition of token sequences in the generated text",presence_penalty:"Limits tokens based on whether they appear in the output or not.",frequency_penalty:"Limits tokens based on how often they appear in the output.",dry_multiplier:"DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the DRY sampling multiplier.",dry_base:"DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the DRY sampling base value.",dry_allowed_length:"DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the allowed length for DRY sampling.",dry_penalty_last_n:"DRY sampling reduces repetition in generated text even across long contexts. This parameter sets DRY penalty for the last n tokens.",max_tokens:"The maximum number of token per output. Use -1 for infinite (no limit).",custom:"Custom JSON parameters to send to the API. Must be valid JSON format.",showTokensPerSecond:"Display generation speed in tokens per second during streaming.",showThoughtInProgress:"Expand thought process by default when generating messages.",disableReasoningFormat:"Show raw LLM output without backend parsing and frontend Markdown rendering to inspect streaming across different models.",keepStatsVisible:"Keep processing statistics visible after generation finishes.",showMessageStats:"Display generation statistics (tokens/second, token count, duration) below each assistant message.",askForTitleConfirmation:"Ask for confirmation before automatically changing conversation title when editing the first message.",pdfAsImage:"Parse PDF as image instead of text (requires vision-capable model).",showModelInfo:"Display the model name used to generate each message below the message content.",renderUserContentAsMarkdown:"Render user messages using markdown formatting in the chat.",modelSelectorEnabled:"Enable the model selector in the chat input to choose the inference model. Sends the associated model field in API requests.",pyInterpreterEnabled:"Enable Python interpreter using Pyodide. Allows running Python code in markdown code blocks."},Q=1e6;function _(f){return typeof f=="number"?Math.round(f*Q)/Q:f}const q=[{key:"temperature",serverKey:"temperature",type:"number",canSync:!0},{key:"top_k",serverKey:"top_k",type:"number",canSync:!0},{key:"top_p",serverKey:"top_p",type:"number",canSync:!0},{key:"min_p",serverKey:"min_p",type:"number",canSync:!0},{key:"dynatemp_range",serverKey:"dynatemp_range",type:"number",canSync:!0},{key:"dynatemp_exponent",serverKey:"dynatemp_exponent",type:"number",canSync:!0},{key:"xtc_probability",serverKey:"xtc_probability",type:"number",canSync:!0},{key:"xtc_threshold",serverKey:"xtc_threshold",type:"number",canSync:!0},{key:"typ_p",serverKey:"typ_p",type:"number",canSync:!0},{key:"repeat_last_n",serverKey:"repeat_last_n",type:"number",canSync:!0},{key:"repeat_penalty",serverKey:"repeat_penalty",type:"number",canSync:!0},{key:"presence_penalty",serverKey:"presence_penalty",type:"number",canSync:!0},{key:"frequency_penalty",serverKey:"frequency_penalty",type:"number",canSync:!0},{key:"dry_multiplier",serverKey:"dry_multiplier",type:"number",canSync:!0},{key:"dry_base",serverKey:"dry_base",type:"number",canSync:!0},{key:"dry_allowed_length",serverKey:"dry_allowed_length",type:"number",canSync:!0},{key:"dry_penalty_last_n",serverKey:"dry_penalty_last_n",type:"number",canSync:!0},{key:"max_tokens",serverKey:"max_tokens",type:"number",canSync:!0},{key:"samplers",serverKey:"samplers",type:"string",canSync:!0}];class E{static roundFloatingPoint(e){return _(e)}static extractServerDefaults(e){if(!e)return{};const t={};for(const r of q)if(r.canSync&&r.serverKey in e){const s=e[r.serverKey];s!==void 0&&(t[r.key]=this.roundFloatingPoint(s))}return e.samplers&&Array.isArray(e.samplers)&&(t.samplers=e.samplers.join(";")),t}static mergeWithServerDefaults(e,t,r=new Set){const s={...e};for(const[n,o]of Object.entries(t))r.has(n)||(s[n]=this.roundFloatingPoint(o));return s}static getParameterInfo(e,t,r,s){const n=r[e]!==void 0,o=s.has(e);return{value:t,source:o?"custom":"default",serverDefault:n?r[e]:void 0,userOverride:o?t:void 0}}static canSyncParameter(e){return q.some(t=>t.key===e&&t.canSync)}static getSyncableParameterKeys(){return q.filter(e=>e.canSync).map(e=>e.key)}static validateServerParameter(e,t){const r=q.find(s=>s.key===e);if(!r)return!1;switch(r.type){case"number":return typeof t=="number"&&!isNaN(t);case"string":return typeof t=="string";case"boolean":return typeof t=="boolean";default:return!1}}static createParameterDiff(e,t){const r={};for(const s of this.getSyncableParameterKeys()){const n=e[s],o=t[s];o!==void 0&&(r[s]={current:n,server:o,differs:n!==o})}return r}}const te="DeltaWebui.selectedModel";class re{static async list(){const t=x().apiKey?.toString().trim(),r=await fetch(`${ee}/v1/models`,{headers:{...t?{Authorization:`Bearer ${t}`}:{}}});if(!r.ok)throw new Error(`Failed to fetch model list (status ${r.status})`);return r.json()}}function se(f,e){let t=e;return{get value(){return t},set value(r){t=r}}}class ne{_models=[];_loading=!1;_updating=!1;_error=null;_selectedModelId=null;_selectedModelName=null;_persistedSelection=se(te,null);constructor(){const e=this._persistedSelection.value;e&&(this._selectedModelId=e.id,this._selectedModelName=e.model)}get models(){return this._models}get loading(){return this._loading}get updating(){return this._updating}get error(){return this._error}get selectedModelId(){return this._selectedModelId}get selectedModelName(){return this._selectedModelName}get selectedModel(){return this._selectedModelId?this._models.find(e=>e.id===this._selectedModelId)??null:null}async fetch(e=!1){if(!this._loading&&!(this._models.length>0&&!e)){this._loading=!0,this._error=null;try{const t=await re.list(),r=t.data.map((n,o)=>{const a=t.models?.[o],i=Array.isArray(a?.capabilities)?a?.capabilities:[],l=a?.name&&a.name.trim().length>0?a.name:n.id,h=this.toDisplayName(l);return{id:n.id,name:h,model:a?.model||n.id,description:a?.description,capabilities:i.filter(b=>!!b),details:a?.details,meta:n.meta??null}});this._models=r;const s=this.determineInitialSelection(r);this._selectedModelId=s.id,this._selectedModelName=s.model,this._persistedSelection.value=s.id&&s.model?{id:s.id,model:s.model}:null}catch(t){throw this._models=[],this._error=t instanceof Error?t.message:"Failed to load models",t}finally{this._loading=!1}}}async select(e){if(!e||this._updating||this._selectedModelId===e)return;const t=this._models.find(r=>r.id===e);if(!t)throw new Error("Selected model is not available");this._updating=!0,this._error=null;try{this._selectedModelId=t.id,this._selectedModelName=t.model,this._persistedSelection.value={id:t.id,model:t.model}}finally{this._updating=!1}}toDisplayName(e){const r=e.split(/\\|\//).pop();return r&&r.trim().length>0?r:e}determineInitialSelection(e){const t=this._persistedSelection.value;let r=this._selectedModelId??t?.id??null,s=this._selectedModelName??t?.model??null;if(r){const n=e.find(o=>o.id===r);n?(r=n.id,s=n.model):e[0]?(r=e[0].id,s=e[0].model):(r=null,s=null)}else e[0]&&(r=e[0].id,s=e[0].model);return{id:r,model:s}}}const y=new ne,ge=()=>y.models,ye=()=>y.loading,ve=()=>y.updating,_e=()=>y.error,Se=()=>y.selectedModelId,oe=()=>y.selectedModelName;y.fetch.bind(y);y.select.bind(y);class ie{callbacks=new Set;isStreamingActive=!1;lastKnownState=null;conversationStates=new Map;activeConversationId=null;startStreaming(){this.isStreamingActive=!0}stopStreaming(){this.isStreamingActive=!1}clearState(){this.lastKnownState=null;for(const e of this.callbacks)try{e(null)}catch(t){console.error("Error in clearState callback:",t)}}isStreaming(){return this.isStreamingActive}setActiveConversation(e){this.activeConversationId=e,this.notifyCallbacks()}updateConversationState(e,t){this.conversationStates.set(e,t),e===this.activeConversationId&&(this.lastKnownState=t,this.notifyCallbacks())}getConversationState(e){return this.conversationStates.get(e)||null}clearConversationState(e){this.conversationStates.delete(e),e===this.activeConversationId&&(this.lastKnownState=null,this.notifyCallbacks())}notifyCallbacks(){const e=this.activeConversationId?this.conversationStates.get(this.activeConversationId)||null:this.lastKnownState;for(const t of this.callbacks)try{t(e)}catch(r){console.error("Error in slots service callback:",r)}}fetchAndNotify(){console.warn("SlotsService.fetchAndNotify() is deprecated - use timing data from ChatService instead")}subscribe(e){return this.callbacks.add(e),this.lastKnownState&&e(this.lastKnownState),()=>{this.callbacks.delete(e)}}async updateFromTimingData(e,t){const r=await this.parseCompletionTimingData(e);if(r===null){console.warn("Failed to parse timing data - skipping update");return}t?this.updateConversationState(t,r):(this.lastKnownState=r,this.notifyCallbacks())}async getContextTotal(){if(this.lastKnownState&&this.lastKnownState.contextTotal>0)return this.lastKnownState.contextTotal;try{const t=x().apiKey?.toString().trim(),r=await fetch("./slots",{headers:{...t?{Authorization:`Bearer ${t}`}:{}}});if(r.ok){const s=await r.json();if(Array.isArray(s)&&s.length>0){const n=s[0];if(n.n_ctx&&n.n_ctx>0)return n.n_ctx}}}catch(e){console.warn("Failed to fetch context total from /slots:",e)}return 4096}async parseCompletionTimingData(e){const t=e.prompt_n||0,r=e.predicted_n||0,s=e.predicted_per_second||0,n=e.cache_n||0,o=e.prompt_progress,a=await this.getContextTotal();if(a===null)return console.warn("No context total available - cannot calculate processing state"),null;const i=x(),l=i.max_tokens||-1,h=t+n+r,b=r,g=o?Math.round(o.processed/o.total*100):void 0;return{status:r>0?"generating":o?"preparing":"idle",tokensDecoded:r,tokensRemaining:l-r,contextUsed:h,contextTotal:a,outputTokensUsed:b,outputTokensMax:l,hasNextToken:r>0,tokensPerSecond:s,temperature:i.temperature??.8,topP:i.top_p??.95,speculative:!1,progressPercent:g,promptTokens:t,cacheTokens:n}}async getCurrentState(){if(this.activeConversationId){const e=this.conversationStates.get(this.activeConversationId);if(e)return e}if(this.lastKnownState)return this.lastKnownState;try{const{chatStore:e}=await import("./chat.svelte.js").then(r=>r.B),t=e.activeMessages;for(let r=t.length-1;r>=0;r--){const s=t[r];if(s.role==="assistant"&&s.timings){const n=await this.parseCompletionTimingData({prompt_n:s.timings.prompt_n||0,predicted_n:s.timings.predicted_n||0,predicted_per_second:s.timings.predicted_n&&s.timings.predicted_ms?s.timings.predicted_n/s.timings.predicted_ms*1e3:0,cache_n:s.timings.cache_n||0});if(n)return this.lastKnownState=n,n}}}catch(e){console.warn("Failed to restore timing data from messages:",e)}return null}}const ae=new ie;class ${abortControllers=new Map;async sendMessage(e,t={},r){const{stream:s,onChunk:n,onComplete:o,onError:a,onReasoningChunk:i,onModel:l,onFirstValidChunk:h,temperature:b,max_tokens:g,dynatemp_range:F,dynatemp_exponent:T,top_k:N,top_p:K,min_p:O,xtc_probability:I,xtc_threshold:v,typ_p:w,repeat_last_n:j,repeat_penalty:R,presence_penalty:L,frequency_penalty:z,dry_multiplier:m,dry_base:M,dry_allowed_length:D,dry_penalty_last_n:k,samplers:C,custom:P,timings_per_token:J}=t,Y=x(),W=r||"default";this.abortControllers.has(W)&&this.abortControllers.get(W)?.abort();const B=new AbortController;this.abortControllers.set(W,B);const Z=e.map(c=>{if("id"in c&&"convId"in c&&"timestamp"in c){const u=c;return $.convertMessageToChatServiceData(u)}else return c}).filter(c=>c.role==="system"?(typeof c.content=="string"?c.content:"").trim().length>0:!0),p={messages:this.injectSystemMessage(Z).map(c=>({role:c.role,content:c.content})),stream:s},G=!!Y.modelSelectorEnabled,H=G?oe():null;if(G&&H&&(p.model=H),p.reasoning_format=Y.disableReasoningFormat?"none":"auto",b!==void 0&&(p.temperature=b),g!==void 0&&(p.max_tokens=g!==null&&g!==0?g:-1),F!==void 0&&(p.dynatemp_range=F),T!==void 0&&(p.dynatemp_exponent=T),N!==void 0&&(p.top_k=N),K!==void 0&&(p.top_p=K),O!==void 0&&(p.min_p=O),I!==void 0&&(p.xtc_probability=I),v!==void 0&&(p.xtc_threshold=v),w!==void 0&&(p.typ_p=w),j!==void 0&&(p.repeat_last_n=j),R!==void 0&&(p.repeat_penalty=R),L!==void 0&&(p.presence_penalty=L),z!==void 0&&(p.frequency_penalty=z),m!==void 0&&(p.dry_multiplier=m),M!==void 0&&(p.dry_base=M),D!==void 0&&(p.dry_allowed_length=D),k!==void 0&&(p.dry_penalty_last_n=k),C!==void 0&&(p.samplers=typeof C=="string"?C.split(";").filter(c=>c.trim()):C),J!==void 0&&(p.timings_per_token=J),P)try{const c=typeof P=="string"?JSON.parse(P):P;Object.assign(p,c)}catch(c){console.warn("Failed to parse custom parameters:",c)}try{const c=Y.apiKey?.toString().trim(),u=await fetch("./v1/chat/completions",{method:"POST",headers:{"Content-Type":"application/json",...c?{Authorization:`Bearer ${c}`}:{}},body:JSON.stringify(p),signal:B.signal});if(!u.ok){const X=await this.parseErrorResponse(u);throw a&&a(X),X}if(s){await this.handleStreamResponse(u,n,o,a,i,l,h,r,B.signal);return}else return this.handleNonStreamResponse(u,o,a,l)}catch(c){if(c instanceof Error&&c.name==="AbortError"){console.log("Chat completion request was aborted");return}let u;throw c instanceof Error?c.name==="TypeError"&&c.message.includes("fetch")?(u=new Error("Unable to connect to server - please check if the server is running"),u.name="NetworkError"):c.message.includes("ECONNREFUSED")?(u=new Error("Connection refused - server may be offline"),u.name="NetworkError"):c.message.includes("ETIMEDOUT")?(u=new Error("Request timed out - the server took too long to respond"),u.name="TimeoutError"):u=c:u=new Error("Unknown error occurred while sending message"),console.error("Error in sendMessage:",c),a&&a(u),u}finally{this.abortControllers.delete(W)}}async handleStreamResponse(e,t,r,s,n,o,a,i,l){const h=e.body?.getReader();if(!h)throw new Error("No response body");const b=new TextDecoder;let g="",F="",T=!1,N,K=!1,O=!1,I=!1;try{let v="";for(;!l?.aborted;){const{done:w,value:j}=await h.read();if(w||l?.aborted)break;v+=b.decode(j,{stream:!0});const R=v.split(`
`);v=R.pop()||"";for(const L of R){if(l?.aborted)break;if(L.startsWith("data: ")){const z=L.slice(6);if(z==="[DONE]"){K=!0;continue}try{const m=JSON.parse(z);!I&&m.object==="chat.completion.chunk"&&(I=!0,l?.aborted||a?.());const M=m.choices[0]?.delta?.content,D=m.choices[0]?.delta?.reasoning_content,k=m.timings,C=m.prompt_progress,P=this.extractModelName(m);P&&!O&&(O=!0,o?.(P)),(k||C)&&(this.updateProcessingState(k,C,i),k&&(N=k)),M&&(T=!0,g+=M,l?.aborted||t?.(M)),D&&(T=!0,F+=D,l?.aborted||n?.(D))}catch(m){console.error("Error parsing JSON chunk:",m)}}}if(l?.aborted)break}if(l?.aborted)return;if(K){if(!T&&g.length===0)throw new Error("No response received from server. Please try again.");r?.(g,F||void 0,N)}}catch(v){const w=v instanceof Error?v:new Error("Stream error");throw s?.(w),w}finally{h.releaseLock()}}async handleNonStreamResponse(e,t,r,s){try{const n=await e.text();if(!n.trim())throw new Error("No response received from server. Please try again.");const o=JSON.parse(n),a=this.extractModelName(o);a&&s?.(a);const i=o.choices[0]?.message?.content||"",l=o.choices[0]?.message?.reasoning_content;if(l&&console.log("Full reasoning content:",l),!i.trim())throw new Error("No response received from server. Please try again.");return t?.(i,l),i}catch(n){const o=n instanceof Error?n:new Error("Parse error");throw r?.(o),o}}static convertMessageToChatServiceData(e){if(!e.extra||e.extra.length===0)return{role:e.role,content:e.content};const t=[];e.content&&t.push({type:"text",text:e.content});const r=e.extra.filter(i=>i.type==="imageFile");for(const i of r)t.push({type:"image_url",image_url:{url:i.base64Url}});const s=e.extra.filter(i=>i.type==="textFile");for(const i of s)t.push({type:"text",text:`

--- File: ${i.name} ---
${i.content}`});const n=e.extra.filter(i=>i.type==="context");for(const i of n)t.push({type:"text",text:`

--- File: ${i.name} ---
${i.content}`});const o=e.extra.filter(i=>i.type==="audioFile");for(const i of o)t.push({type:"input_audio",input_audio:{data:i.base64Data,format:i.mimeType.includes("wav")?"wav":"mp3"}});const a=e.extra.filter(i=>i.type==="pdfFile");for(const i of a)if(i.processedAsImages&&i.images)for(let l=0;l<i.images.length;l++)t.push({type:"image_url",image_url:{url:i.images[l]}});else t.push({type:"text",text:`

--- PDF File: ${i.name} ---
${i.content}`});return{role:e.role,content:t}}static async getServerProps(){try{const t=x().apiKey?.toString().trim(),r=await fetch("./props",{headers:{"Content-Type":"application/json",...t?{Authorization:`Bearer ${t}`}:{}}});if(!r.ok)throw new Error(`Failed to fetch server props: ${r.status}`);return await r.json()}catch(e){throw console.error("Error fetching server props:",e),e}}abort(e){if(e){const t=this.abortControllers.get(e);t&&(t.abort(),this.abortControllers.delete(e))}else{for(const t of this.abortControllers.values())t.abort();this.abortControllers.clear()}}injectSystemMessage(e){const r=x().systemMessage?.toString().trim();if(!r)return e;if(e.length>0&&e[0].role==="system"){if(e[0].content!==r){const n=[...e];return n[0]={role:"system",content:r},n}return e}return[{role:"system",content:r},...e]}async parseErrorResponse(e){try{const t=await e.text(),s=JSON.parse(t).error?.message||"Unknown server error",n=new Error(s);return n.name=e.status===400?"ServerError":"HttpError",n}catch{const t=new Error(`Server error (${e.status}): ${e.statusText}`);return t.name="HttpError",t}}extractModelName(e){const t=l=>typeof l=="object"&&l!==null?l:void 0,r=l=>typeof l=="string"&&l.trim()?l.trim():void 0,s=t(e);if(!s)return;const n=r(s.model);if(n)return n;const o=Array.isArray(s.choices)?t(s.choices[0]):void 0;if(!o)return;const a=r(t(o.delta)?.model);if(a)return a;const i=r(t(o.message)?.model);if(i)return i}updateProcessingState(e,t,r){const s=e?.predicted_ms&&e?.predicted_n?e.predicted_n/e.predicted_ms*1e3:0;ae.updateFromTimingData({prompt_n:e?.prompt_n||0,predicted_n:e?.predicted_n||0,predicted_per_second:s,cache_n:e?.cache_n||0,prompt_progress:t},r).catch(n=>{console.warn("Failed to update processing state:",n)})}}const be=new $;class le{constructor(){}_serverProps=null;_loading=!1;_error=null;_serverWarning=null;_slotsEndpointAvailable=null;fetchServerPropsPromise=null;readCachedServerProps(){return null}persistServerProps(e){}get serverProps(){return this._serverProps}get loading(){return this._loading}get error(){return this._error}get serverWarning(){return this._serverWarning}get modelName(){return this._serverProps?.model_alias?this._serverProps.model_alias:this._serverProps?.model_path&&this._serverProps.model_path.split(/(\\|\/)/).pop()||null}get supportedModalities(){const e=[];return this._serverProps?.modalities?.audio&&e.push("audio"),this._serverProps?.modalities?.vision&&e.push("vision"),e}get supportsVision(){return this._serverProps?.modalities?.vision??!1}get supportsAudio(){return this._serverProps?.modalities?.audio??!1}get slotsEndpointAvailable(){return this._slotsEndpointAvailable}get serverDefaultParams(){return this._serverProps?.default_generation_settings?.params||null}async checkSlotsEndpointAvailability(){if(!this._serverProps){this._slotsEndpointAvailable=!1;return}if(this._serverProps.total_slots<=0){this._slotsEndpointAvailable=!1;return}try{const t=x().apiKey?.toString().trim();if((await fetch("./slots",{headers:{...t?{Authorization:`Bearer ${t}`}:{}}})).status===501){console.info("Slots endpoint not implemented - server started without --slots flag"),this._slotsEndpointAvailable=!1;return}this._slotsEndpointAvailable=!0}catch(e){console.warn("Unable to test slots endpoint availability:",e),this._slotsEndpointAvailable=!1}}async fetchServerProps(e={}){const{silent:t=!1}=e,r=t&&this._serverProps!==null;if(this.fetchServerPropsPromise)return this.fetchServerPropsPromise;r||(this._loading=!0,this._error=null,this._serverWarning=null);const s=this._serverProps!==null,n=(async()=>{try{const o=await $.getServerProps();this._serverProps=o,this.persistServerProps(o),this._error=null,this._serverWarning=null,await this.checkSlotsEndpointAvailability()}catch(o){if(r&&s){console.warn("Silent server props refresh failed, keeping cached data:",o);return}this.handleFetchServerPropsError(o,s)}finally{r||(this._loading=!1),this.fetchServerPropsPromise=null}})();this.fetchServerPropsPromise=n,await n}handleFetchServerPropsError(e,t){const{errorMessage:r,isOfflineLikeError:s,isServerSideError:n}=this.normalizeFetchError(e);let o=null;t?(this._error=null,(s||n)&&(this._serverWarning=r),console.warn("Failed to refresh server properties, continuing with cached values:",r)):(o=this.readCachedServerProps(),o?(this._serverProps=o,this._error=null,(s||n)&&(this._serverWarning=r),console.warn("Failed to refresh server properties, using cached values from localStorage:",r)):this._error=r),console.error("Error fetching server properties:",e)}normalizeFetchError(e){let t="Failed to connect to server",r=!1,s=!1;if(e instanceof Error){const n=e.message||"";e.name==="TypeError"&&n.includes("fetch")?(t="Server is not running or unreachable",r=!0):n.includes("ECONNREFUSED")?(t="Connection refused - server may be offline",r=!0):n.includes("ENOTFOUND")?(t="Server not found - check server address",r=!0):n.includes("ETIMEDOUT")?(t="Request timed out - the server took too long to respond",r=!0):n.includes("503")?(t="Server temporarily unavailable - try again shortly",s=!0):n.includes("500")?(t="Server error - check server logs",s=!0):n.includes("404")?t="Server endpoint not found":(n.includes("403")||n.includes("401"))&&(t="Access denied")}return{errorMessage:t,isOfflineLikeError:r,isServerSideError:s}}clear(){this._serverProps=null,this._error=null,this._serverWarning=null,this._loading=!1,this._slotsEndpointAvailable=null,this.fetchServerPropsPromise=null,this.persistServerProps(null)}}const S=new le,we=()=>S.serverProps,ke=()=>S.loading,Ce=()=>S.error,Pe=()=>S.serverWarning,Ee=()=>S.modelName,xe=()=>S.supportsVision,Te=()=>S.supportsAudio;function U(f,e,t){e in f&&(f[e]=t)}function V(f,e){return f[e]}function ce(f,e){const t={};for(const r of e){const s=V(f,r);s!==void 0&&(t[r]=s)}return t}class de{config={...A};theme="auto";isInitialized=!1;userOverrides=new Set;getServerDefaults(){const e=S.serverDefaultParams;return e?E.extractServerDefaults(e):{}}constructor(){}initialize(){try{this.loadConfig(),this.loadTheme(),this.isInitialized=!0}catch(e){console.error("Failed to initialize settings store:",e)}}loadConfig(){}loadTheme(){}updateConfig(e,t){if(this.config[e]=t,E.canSyncParameter(e)){const s=this.getServerDefaults()[e];if(s!==void 0){const n=_(t),o=_(s);n===o?this.userOverrides.delete(e):this.userOverrides.add(e)}}this.saveConfig()}updateMultipleConfig(e){Object.assign(this.config,e);const t=this.getServerDefaults();for(const[r,s]of Object.entries(e))if(E.canSyncParameter(r)){const n=t[r];if(n!==void 0){const o=_(s),a=_(n);o===a?this.userOverrides.delete(r):this.userOverrides.add(r)}}this.saveConfig()}saveConfig(){}updateTheme(e){this.theme=e,this.saveTheme()}saveTheme(){}resetConfig(){this.config={...A},this.saveConfig()}resetTheme(){this.theme="auto",this.saveTheme()}resetAll(){this.resetConfig(),this.resetTheme()}getConfig(e){return this.config[e]}getAllConfig(){return{...this.config}}syncWithServerDefaults(){if(!S.serverDefaultParams){console.warn("No server parameters available for initialization");return}const t=this.getServerDefaults();for(const[r,s]of Object.entries(t)){const n=V(this.config,r),o=_(n),a=_(s);o===a?(this.userOverrides.delete(r),U(this.config,r,s)):this.userOverrides.has(r)||U(this.config,r,s)}this.saveConfig(),console.log("Settings initialized with props defaults:",t),console.log("Current user overrides after sync:",Array.from(this.userOverrides))}clearAllUserOverrides(){this.userOverrides.clear(),this.saveConfig(),console.log("Cleared all user overrides")}forceSyncWithServerDefaults(){const e=this.getServerDefaults(),t=E.getSyncableParameterKeys();for(const r of t){if(e[r]!==void 0){const s=_(e[r]);U(this.config,r,s)}else if(r in A){const s=V(A,r);U(this.config,r,s)}this.userOverrides.delete(r)}this.saveConfig()}getParameterInfo(e){const t=this.getServerDefaults(),r=V(this.config,e);return E.getParameterInfo(e,r??"",t,this.userOverrides)}resetParameterToServerDefault(e){const t=this.getServerDefaults();if(t[e]!==void 0){const r=_(t[e]);this.config[e]=r}else if(e in A){const r=V(A,e);U(this.config,e,r)}this.userOverrides.delete(e),this.saveConfig()}getParameterDiff(){const e=this.getServerDefaults();if(Object.keys(e).length===0)return{};const t=ce(this.config,E.getSyncableParameterKeys());return E.createParameterDiff(t,e)}}const d=new de,x=()=>d.config,Me=d.updateConfig.bind(d),De=d.updateMultipleConfig.bind(d);d.updateTheme.bind(d);d.resetConfig.bind(d);d.resetTheme.bind(d);d.resetAll.bind(d);d.getConfig.bind(d);d.getAllConfig.bind(d);d.syncWithServerDefaults.bind(d);const Ae=d.forceSyncWithServerDefaults.bind(d),Fe=d.getParameterInfo.bind(d);d.resetParameterToServerDefault.bind(d);d.getParameterDiff.bind(d);d.clearAllUserOverrides.bind(d);export{E as P,A as S,Te as a,ye as b,x as c,ve as d,_e as e,Se as f,ae as g,Ee as h,ke as i,d as j,Pe as k,S as l,ge as m,Ae as n,me as o,Fe as p,Ce as q,we as r,xe as s,Me as t,De as u,be as v};
