import"clsx";import{b as ee}from"./server.js";import"@sveltejs/kit/internal/server";const A={apiKey:"",systemMessage:"",theme:"system",showTokensPerSecond:!1,showThoughtInProgress:!1,disableReasoningFormat:!1,keepStatsVisible:!1,showMessageStats:!0,askForTitleConfirmation:!1,pasteLongTextToFileLen:2500,pdfAsImage:!1,showModelInfo:!1,renderUserContentAsMarkdown:!1,modelSelectorEnabled:!1,samplers:"top_k;typ_p;top_p;min_p;temperature",temperature:.8,dynatemp_range:0,dynatemp_exponent:1,top_k:40,top_p:.95,min_p:.05,xtc_probability:0,xtc_threshold:.1,typ_p:1,repeat_last_n:64,repeat_penalty:1,presence_penalty:0,frequency_penalty:0,dry_multiplier:0,dry_base:1.75,dry_allowed_length:2,dry_penalty_last_n:-1,max_tokens:-1,custom:"",pyInterpreterEnabled:!1},me={apiKey:"Set the API Key if you are using --api-key option for the server.",systemMessage:"The starting message that defines how model should behave.",theme:"Choose the color theme for the interface. You can choose between System (follows your device settings), Light, or Dark.",pasteLongTextToFileLen:"On pasting long text, it will be converted to a file. You can control the file length by setting the value of this parameter. Value 0 means disable.",samplers:'The order at which samplers are applied, in simplified way. Default is "top_k;typ_p;top_p;min_p;temperature": top_k->typ_p->top_p->min_p->temperature',temperature:"Controls the randomness of the generated text by affecting the probability distribution of the output tokens. Higher = more random, lower = more focused.",dynatemp_range:"Addon for the temperature sampler. The added value to the range of dynamic temperature, which adjusts probabilities by entropy of tokens.",dynatemp_exponent:"Addon for the temperature sampler. Smoothes out the probability redistribution based on the most probable token.",top_k:"Keeps only k top tokens.",top_p:"Limits tokens to those that together have a cumulative probability of at least p",min_p:"Limits tokens based on the minimum probability for a token to be considered, relative to the probability of the most likely token.",xtc_probability:"XTC sampler cuts out top tokens; this parameter controls the chance of cutting tokens at all. 0 disables XTC.",xtc_threshold:"XTC sampler cuts out top tokens; this parameter controls the token probability that is required to cut that token.",typ_p:"Sorts and limits tokens based on the difference between log-probability and entropy.",repeat_last_n:"Last n tokens to consider for penalizing repetition",repeat_penalty:"Controls the repetition of token sequences in the generated text",presence_penalty:"Limits tokens based on whether they appear in the output or not.",frequency_penalty:"Limits tokens based on how often they appear in the output.",dry_multiplier:"DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the DRY sampling multiplier.",dry_base:"DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the DRY sampling base value.",dry_allowed_length:"DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the allowed length for DRY sampling.",dry_penalty_last_n:"DRY sampling reduces repetition in generated text even across long contexts. This parameter sets DRY penalty for the last n tokens.",max_tokens:"The maximum number of token per output. Use -1 for infinite (no limit).",custom:"Custom JSON parameters to send to the API. Must be valid JSON format.",showTokensPerSecond:"Display generation speed in tokens per second during streaming.",showThoughtInProgress:"Expand thought process by default when generating messages.",disableReasoningFormat:"Show raw LLM output without backend parsing and frontend Markdown rendering to inspect streaming across different models.",keepStatsVisible:"Keep processing statistics visible after generation finishes.",showMessageStats:"Display generation statistics (tokens/second, token count, duration) below each assistant message.",askForTitleConfirmation:"Ask for confirmation before automatically changing conversation title when editing the first message.",pdfAsImage:"Parse PDF as image instead of text (requires vision-capable model).",showModelInfo:"Display the model name used to generate each message below the message content.",renderUserContentAsMarkdown:"Render user messages using markdown formatting in the chat.",modelSelectorEnabled:"Enable the model selector in the chat input to choose the inference model. Sends the associated model field in API requests.",pyInterpreterEnabled:"Enable Python interpreter using Pyodide. Allows running Python code in markdown code blocks."},Q=1e6;function _(h){return typeof h=="number"?Math.round(h*Q)/Q:h}const W=[{key:"temperature",serverKey:"temperature",type:"number",canSync:!0},{key:"top_k",serverKey:"top_k",type:"number",canSync:!0},{key:"top_p",serverKey:"top_p",type:"number",canSync:!0},{key:"min_p",serverKey:"min_p",type:"number",canSync:!0},{key:"dynatemp_range",serverKey:"dynatemp_range",type:"number",canSync:!0},{key:"dynatemp_exponent",serverKey:"dynatemp_exponent",type:"number",canSync:!0},{key:"xtc_probability",serverKey:"xtc_probability",type:"number",canSync:!0},{key:"xtc_threshold",serverKey:"xtc_threshold",type:"number",canSync:!0},{key:"typ_p",serverKey:"typ_p",type:"number",canSync:!0},{key:"repeat_last_n",serverKey:"repeat_last_n",type:"number",canSync:!0},{key:"repeat_penalty",serverKey:"repeat_penalty",type:"number",canSync:!0},{key:"presence_penalty",serverKey:"presence_penalty",type:"number",canSync:!0},{key:"frequency_penalty",serverKey:"frequency_penalty",type:"number",canSync:!0},{key:"dry_multiplier",serverKey:"dry_multiplier",type:"number",canSync:!0},{key:"dry_base",serverKey:"dry_base",type:"number",canSync:!0},{key:"dry_allowed_length",serverKey:"dry_allowed_length",type:"number",canSync:!0},{key:"dry_penalty_last_n",serverKey:"dry_penalty_last_n",type:"number",canSync:!0},{key:"max_tokens",serverKey:"max_tokens",type:"number",canSync:!0},{key:"samplers",serverKey:"samplers",type:"string",canSync:!0}];class P{static roundFloatingPoint(e){return _(e)}static extractServerDefaults(e){if(!e)return{};const t={};for(const r of W)if(r.canSync&&r.serverKey in e){const s=e[r.serverKey];s!==void 0&&(t[r.key]=this.roundFloatingPoint(s))}return e.samplers&&Array.isArray(e.samplers)&&(t.samplers=e.samplers.join(";")),t}static mergeWithServerDefaults(e,t,r=new Set){const s={...e};for(const[o,n]of Object.entries(t))r.has(o)||(s[o]=this.roundFloatingPoint(n));return s}static getParameterInfo(e,t,r,s){const o=r[e]!==void 0,n=s.has(e);return{value:t,source:n?"custom":"default",serverDefault:o?r[e]:void 0,userOverride:n?t:void 0}}static canSyncParameter(e){return W.some(t=>t.key===e&&t.canSync)}static getSyncableParameterKeys(){return W.filter(e=>e.canSync).map(e=>e.key)}static validateServerParameter(e,t){const r=W.find(s=>s.key===e);if(!r)return!1;switch(r.type){case"number":return typeof t=="number"&&!isNaN(t);case"string":return typeof t=="string";case"boolean":return typeof t=="boolean";default:return!1}}static createParameterDiff(e,t){const r={};for(const s of this.getSyncableParameterKeys()){const o=e[s],n=t[s];n!==void 0&&(r[s]={current:o,server:n,differs:o!==n})}return r}}const te="DeltaWebui.selectedModel";class re{static async list(){const t=x().apiKey?.toString().trim(),r=await fetch(`${ee}/v1/models`,{headers:{...t?{Authorization:`Bearer ${t}`}:{}}});if(!r.ok)throw new Error(`Failed to fetch model list (status ${r.status})`);return r.json()}static async listAvailable(){const e=await fetch("http://localhost:8081/api/models/available",{method:"GET",headers:{"Content-Type":"application/json"}});if(!e.ok)throw new Error(`Failed to fetch available models (status ${e.status})`);return e.json()}static async listInstalled(){const e=await fetch("http://localhost:8081/api/models/list",{method:"GET",headers:{"Content-Type":"application/json"}});if(!e.ok)throw new Error(`Failed to fetch installed models (status ${e.status})`);return e.json()}static async download(e){const t=await fetch("http://localhost:8081/api/models/download",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({model:e})});if(!t.ok){const r=await t.json().catch(()=>({}));throw new Error(r.error?.message||`Failed to download model (status ${t.status})`)}return t.json()}static async remove(e){const t=await fetch(`http://localhost:8081/api/models/${encodeURIComponent(e)}`,{method:"DELETE",headers:{"Content-Type":"application/json"}});if(!t.ok){const r=await t.json().catch(()=>({}));throw new Error(r.error?.message||`Failed to remove model (status ${t.status})`)}return t.json()}static async use(e){const t=await fetch("http://localhost:8081/api/models/use",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({model:e})});if(!t.ok){const r=await t.json().catch(()=>({}));throw new Error(r.error?.message||`Failed to switch model (status ${t.status})`)}return t.json()}}function se(h,e){let t=e;return{get value(){return t},set value(r){t=r}}}class oe{_models=[];_loading=!1;_updating=!1;_error=null;_selectedModelId=null;_selectedModelName=null;_persistedSelection=se(te,null);constructor(){const e=this._persistedSelection.value;e&&(this._selectedModelId=e.id,this._selectedModelName=e.model)}get models(){return this._models}get loading(){return this._loading}get updating(){return this._updating}get error(){return this._error}get selectedModelId(){return this._selectedModelId}get selectedModelName(){return this._selectedModelName}get selectedModel(){return this._selectedModelId?this._models.find(e=>e.id===this._selectedModelId)??null:null}async fetch(e=!1){if(!this._loading&&!(this._models.length>0&&!e)){this._loading=!0,this._error=null;try{const t=await re.list(),r=t.data.map((o,n)=>{const a=t.models?.[n],i=Array.isArray(a?.capabilities)?a?.capabilities:[],l=a?.name&&a.name.trim().length>0?a.name:o.id,f=this.toDisplayName(l);return{id:o.id,name:f,model:a?.model||o.id,description:a?.description,capabilities:i.filter(S=>!!S),details:a?.details,meta:o.meta??null}});this._models=r;const s=this.determineInitialSelection(r);this._selectedModelId=s.id,this._selectedModelName=s.model,this._persistedSelection.value=s.id&&s.model?{id:s.id,model:s.model}:null}catch(t){throw this._models=[],this._error=t instanceof Error?t.message:"Failed to load models",t}finally{this._loading=!1}}}async select(e){if(!e||this._updating||this._selectedModelId===e)return;const t=this._models.find(r=>r.id===e);if(!t)throw new Error("Selected model is not available");this._updating=!0,this._error=null;try{this._selectedModelId=t.id,this._selectedModelName=t.model,this._persistedSelection.value={id:t.id,model:t.model}}finally{this._updating=!1}}toDisplayName(e){const r=e.split(/\\|\//).pop();return r&&r.trim().length>0?r:e}determineInitialSelection(e){const t=this._persistedSelection.value;let r=this._selectedModelId??t?.id??null,s=this._selectedModelName??t?.model??null;if(r){const o=e.find(n=>n.id===r);o?(r=o.id,s=o.model):e[0]?(r=e[0].id,s=e[0].model):(r=null,s=null)}else e[0]&&(r=e[0].id,s=e[0].model);return{id:r,model:s}}}const y=new oe,ge=()=>y.models,ye=()=>y.loading,ve=()=>y.updating,_e=()=>y.error,be=()=>y.selectedModelId,ne=()=>y.selectedModelName;y.fetch.bind(y);y.select.bind(y);class ie{callbacks=new Set;isStreamingActive=!1;lastKnownState=null;conversationStates=new Map;activeConversationId=null;startStreaming(){this.isStreamingActive=!0}stopStreaming(){this.isStreamingActive=!1}clearState(){this.lastKnownState=null;for(const e of this.callbacks)try{e(null)}catch(t){console.error("Error in clearState callback:",t)}}isStreaming(){return this.isStreamingActive}setActiveConversation(e){this.activeConversationId=e,this.notifyCallbacks()}updateConversationState(e,t){this.conversationStates.set(e,t),e===this.activeConversationId&&(this.lastKnownState=t,this.notifyCallbacks())}getConversationState(e){return this.conversationStates.get(e)||null}clearConversationState(e){this.conversationStates.delete(e),e===this.activeConversationId&&(this.lastKnownState=null,this.notifyCallbacks())}notifyCallbacks(){const e=this.activeConversationId?this.conversationStates.get(this.activeConversationId)||null:this.lastKnownState;for(const t of this.callbacks)try{t(e)}catch(r){console.error("Error in slots service callback:",r)}}fetchAndNotify(){console.warn("SlotsService.fetchAndNotify() is deprecated - use timing data from ChatService instead")}subscribe(e){return this.callbacks.add(e),this.lastKnownState&&e(this.lastKnownState),()=>{this.callbacks.delete(e)}}async updateFromTimingData(e,t){const r=await this.parseCompletionTimingData(e);if(r===null){console.warn("Failed to parse timing data - skipping update");return}t?this.updateConversationState(t,r):(this.lastKnownState=r,this.notifyCallbacks())}async getContextTotal(){if(this.lastKnownState&&this.lastKnownState.contextTotal>0)return this.lastKnownState.contextTotal;try{const t=x().apiKey?.toString().trim(),r=await fetch("./slots",{headers:{...t?{Authorization:`Bearer ${t}`}:{}}});if(r.ok){const s=await r.json();if(Array.isArray(s)&&s.length>0){const o=s[0];if(o.n_ctx&&o.n_ctx>0)return o.n_ctx}}}catch(e){console.warn("Failed to fetch context total from /slots:",e)}return 4096}async parseCompletionTimingData(e){const t=e.prompt_n||0,r=e.predicted_n||0,s=e.predicted_per_second||0,o=e.cache_n||0,n=e.prompt_progress,a=await this.getContextTotal();if(a===null)return console.warn("No context total available - cannot calculate processing state"),null;const i=x(),l=i.max_tokens||-1,f=t+o+r,S=r,g=n?Math.round(n.processed/n.total*100):void 0;return{status:r>0?"generating":n?"preparing":"idle",tokensDecoded:r,tokensRemaining:l-r,contextUsed:f,contextTotal:a,outputTokensUsed:S,outputTokensMax:l,hasNextToken:r>0,tokensPerSecond:s,temperature:i.temperature??.8,topP:i.top_p??.95,speculative:!1,progressPercent:g,promptTokens:t,cacheTokens:o}}async getCurrentState(){if(this.activeConversationId){const e=this.conversationStates.get(this.activeConversationId);if(e)return e}if(this.lastKnownState)return this.lastKnownState;try{const{chatStore:e}=await import("./chat.svelte.js").then(r=>r.B),t=e.activeMessages;for(let r=t.length-1;r>=0;r--){const s=t[r];if(s.role==="assistant"&&s.timings){const o=await this.parseCompletionTimingData({prompt_n:s.timings.prompt_n||0,predicted_n:s.timings.predicted_n||0,predicted_per_second:s.timings.predicted_n&&s.timings.predicted_ms?s.timings.predicted_n/s.timings.predicted_ms*1e3:0,cache_n:s.timings.cache_n||0});if(o)return this.lastKnownState=o,o}}}catch(e){console.warn("Failed to restore timing data from messages:",e)}return null}}const ae=new ie;class q{abortControllers=new Map;async sendMessage(e,t={},r){const{stream:s,onChunk:o,onComplete:n,onError:a,onReasoningChunk:i,onModel:l,onFirstValidChunk:f,temperature:S,max_tokens:g,dynatemp_range:F,dynatemp_exponent:T,top_k:N,top_p:K,min_p:O,xtc_probability:I,xtc_threshold:v,typ_p:w,repeat_last_n:$,repeat_penalty:R,presence_penalty:j,frequency_penalty:L,dry_multiplier:m,dry_base:M,dry_allowed_length:D,dry_penalty_last_n:k,samplers:C,custom:E,timings_per_token:J}=t,Y=x(),V=r||"default";this.abortControllers.has(V)&&this.abortControllers.get(V)?.abort();const B=new AbortController;this.abortControllers.set(V,B);const Z=e.map(c=>{if("id"in c&&"convId"in c&&"timestamp"in c){const u=c;return q.convertMessageToChatServiceData(u)}else return c}).filter(c=>c.role==="system"?(typeof c.content=="string"?c.content:"").trim().length>0:!0),p={messages:this.injectSystemMessage(Z).map(c=>({role:c.role,content:c.content})),stream:s},G=!!Y.modelSelectorEnabled,H=G?ne():null;if(G&&H&&(p.model=H),p.reasoning_format=Y.disableReasoningFormat?"none":"auto",S!==void 0&&(p.temperature=S),g!==void 0&&(p.max_tokens=g!==null&&g!==0?g:-1),F!==void 0&&(p.dynatemp_range=F),T!==void 0&&(p.dynatemp_exponent=T),N!==void 0&&(p.top_k=N),K!==void 0&&(p.top_p=K),O!==void 0&&(p.min_p=O),I!==void 0&&(p.xtc_probability=I),v!==void 0&&(p.xtc_threshold=v),w!==void 0&&(p.typ_p=w),$!==void 0&&(p.repeat_last_n=$),R!==void 0&&(p.repeat_penalty=R),j!==void 0&&(p.presence_penalty=j),L!==void 0&&(p.frequency_penalty=L),m!==void 0&&(p.dry_multiplier=m),M!==void 0&&(p.dry_base=M),D!==void 0&&(p.dry_allowed_length=D),k!==void 0&&(p.dry_penalty_last_n=k),C!==void 0&&(p.samplers=typeof C=="string"?C.split(";").filter(c=>c.trim()):C),J!==void 0&&(p.timings_per_token=J),E)try{const c=typeof E=="string"?JSON.parse(E):E;Object.assign(p,c)}catch(c){console.warn("Failed to parse custom parameters:",c)}try{const c=Y.apiKey?.toString().trim(),u=await fetch("./v1/chat/completions",{method:"POST",headers:{"Content-Type":"application/json",...c?{Authorization:`Bearer ${c}`}:{}},body:JSON.stringify(p),signal:B.signal});if(!u.ok){const X=await this.parseErrorResponse(u);throw a&&a(X),X}if(s){await this.handleStreamResponse(u,o,n,a,i,l,f,r,B.signal);return}else return this.handleNonStreamResponse(u,n,a,l)}catch(c){if(c instanceof Error&&c.name==="AbortError"){console.log("Chat completion request was aborted");return}let u;throw c instanceof Error?c.name==="TypeError"&&c.message.includes("fetch")?(u=new Error("Unable to connect to server - please check if the server is running"),u.name="NetworkError"):c.message.includes("ECONNREFUSED")?(u=new Error("Connection refused - server may be offline"),u.name="NetworkError"):c.message.includes("ETIMEDOUT")?(u=new Error("Request timed out - the server took too long to respond"),u.name="TimeoutError"):u=c:u=new Error("Unknown error occurred while sending message"),console.error("Error in sendMessage:",c),a&&a(u),u}finally{this.abortControllers.delete(V)}}async handleStreamResponse(e,t,r,s,o,n,a,i,l){const f=e.body?.getReader();if(!f)throw new Error("No response body");const S=new TextDecoder;let g="",F="",T=!1,N,K=!1,O=!1,I=!1;try{let v="";for(;!l?.aborted;){const{done:w,value:$}=await f.read();if(w||l?.aborted)break;v+=S.decode($,{stream:!0});const R=v.split(`
`);v=R.pop()||"";for(const j of R){if(l?.aborted)break;if(j.startsWith("data: ")){const L=j.slice(6);if(L==="[DONE]"){K=!0;continue}try{const m=JSON.parse(L);!I&&m.object==="chat.completion.chunk"&&(I=!0,l?.aborted||a?.());const M=m.choices[0]?.delta?.content,D=m.choices[0]?.delta?.reasoning_content,k=m.timings,C=m.prompt_progress,E=this.extractModelName(m);E&&!O&&(O=!0,n?.(E)),(k||C)&&(this.updateProcessingState(k,C,i),k&&(N=k)),M&&(T=!0,g+=M,l?.aborted||t?.(M)),D&&(T=!0,F+=D,l?.aborted||o?.(D))}catch(m){console.error("Error parsing JSON chunk:",m)}}}if(l?.aborted)break}if(l?.aborted)return;if(K){if(!T&&g.length===0)throw new Error("No response received from server. Please try again.");r?.(g,F||void 0,N)}}catch(v){const w=v instanceof Error?v:new Error("Stream error");throw s?.(w),w}finally{f.releaseLock()}}async handleNonStreamResponse(e,t,r,s){try{const o=await e.text();if(!o.trim())throw new Error("No response received from server. Please try again.");const n=JSON.parse(o),a=this.extractModelName(n);a&&s?.(a);const i=n.choices[0]?.message?.content||"",l=n.choices[0]?.message?.reasoning_content;if(l&&console.log("Full reasoning content:",l),!i.trim())throw new Error("No response received from server. Please try again.");return t?.(i,l),i}catch(o){const n=o instanceof Error?o:new Error("Parse error");throw r?.(n),n}}static convertMessageToChatServiceData(e){if(!e.extra||e.extra.length===0)return{role:e.role,content:e.content};const t=[];e.content&&t.push({type:"text",text:e.content});const r=e.extra.filter(i=>i.type==="imageFile");for(const i of r)t.push({type:"image_url",image_url:{url:i.base64Url}});const s=e.extra.filter(i=>i.type==="textFile");for(const i of s)t.push({type:"text",text:`

--- File: ${i.name} ---
${i.content}`});const o=e.extra.filter(i=>i.type==="context");for(const i of o)t.push({type:"text",text:`

--- File: ${i.name} ---
${i.content}`});const n=e.extra.filter(i=>i.type==="audioFile");for(const i of n)t.push({type:"input_audio",input_audio:{data:i.base64Data,format:i.mimeType.includes("wav")?"wav":"mp3"}});const a=e.extra.filter(i=>i.type==="pdfFile");for(const i of a)if(i.processedAsImages&&i.images)for(let l=0;l<i.images.length;l++)t.push({type:"image_url",image_url:{url:i.images[l]}});else t.push({type:"text",text:`

--- PDF File: ${i.name} ---
${i.content}`});return{role:e.role,content:t}}static async getServerProps(){try{const t=x().apiKey?.toString().trim(),r=await fetch("./props",{headers:{"Content-Type":"application/json",...t?{Authorization:`Bearer ${t}`}:{}}});if(!r.ok)throw new Error(`Failed to fetch server props: ${r.status}`);return await r.json()}catch(e){throw console.error("Error fetching server props:",e),e}}abort(e){if(e){const t=this.abortControllers.get(e);t&&(t.abort(),this.abortControllers.delete(e))}else{for(const t of this.abortControllers.values())t.abort();this.abortControllers.clear()}}injectSystemMessage(e){const r=x().systemMessage?.toString().trim();if(!r)return e;if(e.length>0&&e[0].role==="system"){if(e[0].content!==r){const o=[...e];return o[0]={role:"system",content:r},o}return e}return[{role:"system",content:r},...e]}async parseErrorResponse(e){try{const t=await e.text(),s=JSON.parse(t).error?.message||"Unknown server error",o=new Error(s);return o.name=e.status===400?"ServerError":"HttpError",o}catch{const t=new Error(`Server error (${e.status}): ${e.statusText}`);return t.name="HttpError",t}}extractModelName(e){const t=l=>typeof l=="object"&&l!==null?l:void 0,r=l=>typeof l=="string"&&l.trim()?l.trim():void 0,s=t(e);if(!s)return;const o=r(s.model);if(o)return o;const n=Array.isArray(s.choices)?t(s.choices[0]):void 0;if(!n)return;const a=r(t(n.delta)?.model);if(a)return a;const i=r(t(n.message)?.model);if(i)return i}updateProcessingState(e,t,r){const s=e?.predicted_ms&&e?.predicted_n?e.predicted_n/e.predicted_ms*1e3:0;ae.updateFromTimingData({prompt_n:e?.prompt_n||0,predicted_n:e?.predicted_n||0,predicted_per_second:s,cache_n:e?.cache_n||0,prompt_progress:t},r).catch(o=>{console.warn("Failed to update processing state:",o)})}}const Se=new q;class le{constructor(){}_serverProps=null;_loading=!1;_error=null;_serverWarning=null;_slotsEndpointAvailable=null;fetchServerPropsPromise=null;readCachedServerProps(){return null}persistServerProps(e){}get serverProps(){return this._serverProps}get loading(){return this._loading}get error(){return this._error}get serverWarning(){return this._serverWarning}get modelName(){return this._serverProps?.model_alias?this._serverProps.model_alias:this._serverProps?.model_path&&this._serverProps.model_path.split(/(\\|\/)/).pop()||null}get supportedModalities(){const e=[];return this._serverProps?.modalities?.audio&&e.push("audio"),this._serverProps?.modalities?.vision&&e.push("vision"),e}get supportsVision(){return this._serverProps?.modalities?.vision??!1}get supportsAudio(){return this._serverProps?.modalities?.audio??!1}get slotsEndpointAvailable(){return this._slotsEndpointAvailable}get serverDefaultParams(){return this._serverProps?.default_generation_settings?.params||null}async checkSlotsEndpointAvailability(){if(!this._serverProps){this._slotsEndpointAvailable=!1;return}if(this._serverProps.total_slots<=0){this._slotsEndpointAvailable=!1;return}try{const t=x().apiKey?.toString().trim();if((await fetch("./slots",{headers:{...t?{Authorization:`Bearer ${t}`}:{}}})).status===501){console.info("Slots endpoint not implemented - server started without --slots flag"),this._slotsEndpointAvailable=!1;return}this._slotsEndpointAvailable=!0}catch(e){console.warn("Unable to test slots endpoint availability:",e),this._slotsEndpointAvailable=!1}}async fetchServerProps(e={}){const{silent:t=!1}=e,r=t&&this._serverProps!==null;if(this.fetchServerPropsPromise)return this.fetchServerPropsPromise;r||(this._loading=!0,this._error=null,this._serverWarning=null);const s=this._serverProps!==null,o=(async()=>{try{const n=await q.getServerProps();this._serverProps=n,this.persistServerProps(n),this._error=null,this._serverWarning=null,await this.checkSlotsEndpointAvailability()}catch(n){if(r&&s){console.warn("Silent server props refresh failed, keeping cached data:",n);return}this.handleFetchServerPropsError(n,s)}finally{r||(this._loading=!1),this.fetchServerPropsPromise=null}})();this.fetchServerPropsPromise=o,await o}handleFetchServerPropsError(e,t){const{errorMessage:r,isOfflineLikeError:s,isServerSideError:o}=this.normalizeFetchError(e);let n=null;t?(this._error=null,(s||o)&&(this._serverWarning=r),console.warn("Failed to refresh server properties, continuing with cached values:",r)):(n=this.readCachedServerProps(),n?(this._serverProps=n,this._error=null,(s||o)&&(this._serverWarning=r),console.warn("Failed to refresh server properties, using cached values from localStorage:",r)):this._error=r),console.error("Error fetching server properties:",e)}normalizeFetchError(e){let t="Failed to connect to server",r=!1,s=!1;if(e instanceof Error){const o=e.message||"";e.name==="TypeError"&&o.includes("fetch")?(t="Server is not running or unreachable",r=!0):o.includes("ECONNREFUSED")?(t="Connection refused - server may be offline",r=!0):o.includes("ENOTFOUND")?(t="Server not found - check server address",r=!0):o.includes("ETIMEDOUT")?(t="Request timed out - the server took too long to respond",r=!0):o.includes("503")?(t="Server temporarily unavailable - try again shortly",s=!0):o.includes("500")?(t="Server error - check server logs",s=!0):o.includes("404")?t="Server endpoint not found":(o.includes("403")||o.includes("401"))&&(t="Access denied")}return{errorMessage:t,isOfflineLikeError:r,isServerSideError:s}}clear(){this._serverProps=null,this._error=null,this._serverWarning=null,this._loading=!1,this._slotsEndpointAvailable=null,this.fetchServerPropsPromise=null,this.persistServerProps(null)}}const b=new le,we=()=>b.serverProps,ke=()=>b.loading,Ce=()=>b.error,Ee=()=>b.serverWarning,Pe=()=>b.modelName,xe=()=>b.supportsVision,Te=()=>b.supportsAudio;function z(h,e,t){e in h&&(h[e]=t)}function U(h,e){return h[e]}function ce(h,e){const t={};for(const r of e){const s=U(h,r);s!==void 0&&(t[r]=s)}return t}class de{config={...A};theme="auto";isInitialized=!1;userOverrides=new Set;getServerDefaults(){const e=b.serverDefaultParams;return e?P.extractServerDefaults(e):{}}constructor(){}initialize(){try{this.loadConfig(),this.loadTheme(),this.isInitialized=!0}catch(e){console.error("Failed to initialize settings store:",e)}}loadConfig(){}loadTheme(){}updateConfig(e,t){if(this.config[e]=t,P.canSyncParameter(e)){const s=this.getServerDefaults()[e];if(s!==void 0){const o=_(t),n=_(s);o===n?this.userOverrides.delete(e):this.userOverrides.add(e)}}this.saveConfig()}updateMultipleConfig(e){Object.assign(this.config,e);const t=this.getServerDefaults();for(const[r,s]of Object.entries(e))if(P.canSyncParameter(r)){const o=t[r];if(o!==void 0){const n=_(s),a=_(o);n===a?this.userOverrides.delete(r):this.userOverrides.add(r)}}this.saveConfig()}saveConfig(){}updateTheme(e){this.theme=e,this.saveTheme()}saveTheme(){}resetConfig(){this.config={...A},this.saveConfig()}resetTheme(){this.theme="auto",this.saveTheme()}resetAll(){this.resetConfig(),this.resetTheme()}getConfig(e){return this.config[e]}getAllConfig(){return{...this.config}}syncWithServerDefaults(){if(!b.serverDefaultParams){console.warn("No server parameters available for initialization");return}const t=this.getServerDefaults();for(const[r,s]of Object.entries(t)){const o=U(this.config,r),n=_(o),a=_(s);n===a?(this.userOverrides.delete(r),z(this.config,r,s)):this.userOverrides.has(r)||z(this.config,r,s)}this.saveConfig(),console.log("Settings initialized with props defaults:",t),console.log("Current user overrides after sync:",Array.from(this.userOverrides))}clearAllUserOverrides(){this.userOverrides.clear(),this.saveConfig(),console.log("Cleared all user overrides")}forceSyncWithServerDefaults(){const e=this.getServerDefaults(),t=P.getSyncableParameterKeys();for(const r of t){if(e[r]!==void 0){const s=_(e[r]);z(this.config,r,s)}else if(r in A){const s=U(A,r);z(this.config,r,s)}this.userOverrides.delete(r)}this.saveConfig()}getParameterInfo(e){const t=this.getServerDefaults(),r=U(this.config,e);return P.getParameterInfo(e,r??"",t,this.userOverrides)}resetParameterToServerDefault(e){const t=this.getServerDefaults();if(t[e]!==void 0){const r=_(t[e]);this.config[e]=r}else if(e in A){const r=U(A,e);z(this.config,e,r)}this.userOverrides.delete(e),this.saveConfig()}getParameterDiff(){const e=this.getServerDefaults();if(Object.keys(e).length===0)return{};const t=ce(this.config,P.getSyncableParameterKeys());return P.createParameterDiff(t,e)}}const d=new de,x=()=>d.config,Me=d.updateConfig.bind(d),De=d.updateMultipleConfig.bind(d);d.updateTheme.bind(d);d.resetConfig.bind(d);d.resetTheme.bind(d);d.resetAll.bind(d);d.getConfig.bind(d);d.getAllConfig.bind(d);d.syncWithServerDefaults.bind(d);const Ae=d.forceSyncWithServerDefaults.bind(d),Fe=d.getParameterInfo.bind(d);d.resetParameterToServerDefault.bind(d);d.getParameterDiff.bind(d);d.clearAllUserOverrides.bind(d);export{re as M,P,A as S,Te as a,ye as b,x as c,ve as d,_e as e,be as f,ae as g,Pe as h,ke as i,d as j,Ee as k,b as l,ge as m,Ae as n,me as o,Fe as p,Ce as q,we as r,xe as s,Me as t,De as u,Se as v};
