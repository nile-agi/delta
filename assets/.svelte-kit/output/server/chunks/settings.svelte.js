import"clsx";import{b as te}from"./server.js";import"@sveltejs/kit/internal/server";const I={apiKey:"",systemMessage:"",theme:"system",showTokensPerSecond:!1,showThoughtInProgress:!1,disableReasoningFormat:!1,keepStatsVisible:!1,showMessageStats:!0,askForTitleConfirmation:!1,pasteLongTextToFileLen:2500,pdfAsImage:!1,showModelInfo:!1,renderUserContentAsMarkdown:!1,modelSelectorEnabled:!1,samplers:"top_k;typ_p;top_p;min_p;temperature",temperature:.8,dynatemp_range:0,dynatemp_exponent:1,top_k:40,top_p:.95,min_p:.05,xtc_probability:0,xtc_threshold:.1,typ_p:1,repeat_last_n:64,repeat_penalty:1,presence_penalty:0,frequency_penalty:0,dry_multiplier:0,dry_base:1.75,dry_allowed_length:2,dry_penalty_last_n:-1,max_tokens:-1,custom:"",pyInterpreterEnabled:!1},me={apiKey:"Set the API Key if you are using --api-key option for the server.",systemMessage:"The starting message that defines how model should behave.",theme:"Choose the color theme for the interface. You can choose between System (follows your device settings), Light, or Dark.",pasteLongTextToFileLen:"On pasting long text, it will be converted to a file. You can control the file length by setting the value of this parameter. Value 0 means disable.",samplers:'The order at which samplers are applied, in simplified way. Default is "top_k;typ_p;top_p;min_p;temperature": top_k->typ_p->top_p->min_p->temperature',temperature:"Controls the randomness of the generated text by affecting the probability distribution of the output tokens. Higher = more random, lower = more focused.",dynatemp_range:"Addon for the temperature sampler. The added value to the range of dynamic temperature, which adjusts probabilities by entropy of tokens.",dynatemp_exponent:"Addon for the temperature sampler. Smoothes out the probability redistribution based on the most probable token.",top_k:"Keeps only k top tokens.",top_p:"Limits tokens to those that together have a cumulative probability of at least p",min_p:"Limits tokens based on the minimum probability for a token to be considered, relative to the probability of the most likely token.",xtc_probability:"XTC sampler cuts out top tokens; this parameter controls the chance of cutting tokens at all. 0 disables XTC.",xtc_threshold:"XTC sampler cuts out top tokens; this parameter controls the token probability that is required to cut that token.",typ_p:"Sorts and limits tokens based on the difference between log-probability and entropy.",repeat_last_n:"Last n tokens to consider for penalizing repetition",repeat_penalty:"Controls the repetition of token sequences in the generated text",presence_penalty:"Limits tokens based on whether they appear in the output or not.",frequency_penalty:"Limits tokens based on how often they appear in the output.",dry_multiplier:"DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the DRY sampling multiplier.",dry_base:"DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the DRY sampling base value.",dry_allowed_length:"DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the allowed length for DRY sampling.",dry_penalty_last_n:"DRY sampling reduces repetition in generated text even across long contexts. This parameter sets DRY penalty for the last n tokens.",max_tokens:"The maximum number of token per output. Use -1 for infinite (no limit).",custom:"Custom JSON parameters to send to the API. Must be valid JSON format.",showTokensPerSecond:"Display generation speed in tokens per second during streaming.",showThoughtInProgress:"Expand thought process by default when generating messages.",disableReasoningFormat:"Show raw LLM output without backend parsing and frontend Markdown rendering to inspect streaming across different models.",keepStatsVisible:"Keep processing statistics visible after generation finishes.",showMessageStats:"Display generation statistics (tokens/second, token count, duration) below each assistant message.",askForTitleConfirmation:"Ask for confirmation before automatically changing conversation title when editing the first message.",pdfAsImage:"Parse PDF as image instead of text (requires vision-capable model).",showModelInfo:"Display the model name used to generate each message below the message content.",renderUserContentAsMarkdown:"Render user messages using markdown formatting in the chat.",modelSelectorEnabled:"Enable the model selector in the chat input to choose the inference model. Sends the associated model field in API requests.",pyInterpreterEnabled:"Enable Python interpreter using Pyodide. Allows running Python code in markdown code blocks."},Z=1e6;function b(m){return typeof m=="number"?Math.round(m*Z)/Z:m}const q=[{key:"temperature",serverKey:"temperature",type:"number",canSync:!0},{key:"top_k",serverKey:"top_k",type:"number",canSync:!0},{key:"top_p",serverKey:"top_p",type:"number",canSync:!0},{key:"min_p",serverKey:"min_p",type:"number",canSync:!0},{key:"dynatemp_range",serverKey:"dynatemp_range",type:"number",canSync:!0},{key:"dynatemp_exponent",serverKey:"dynatemp_exponent",type:"number",canSync:!0},{key:"xtc_probability",serverKey:"xtc_probability",type:"number",canSync:!0},{key:"xtc_threshold",serverKey:"xtc_threshold",type:"number",canSync:!0},{key:"typ_p",serverKey:"typ_p",type:"number",canSync:!0},{key:"repeat_last_n",serverKey:"repeat_last_n",type:"number",canSync:!0},{key:"repeat_penalty",serverKey:"repeat_penalty",type:"number",canSync:!0},{key:"presence_penalty",serverKey:"presence_penalty",type:"number",canSync:!0},{key:"frequency_penalty",serverKey:"frequency_penalty",type:"number",canSync:!0},{key:"dry_multiplier",serverKey:"dry_multiplier",type:"number",canSync:!0},{key:"dry_base",serverKey:"dry_base",type:"number",canSync:!0},{key:"dry_allowed_length",serverKey:"dry_allowed_length",type:"number",canSync:!0},{key:"dry_penalty_last_n",serverKey:"dry_penalty_last_n",type:"number",canSync:!0},{key:"max_tokens",serverKey:"max_tokens",type:"number",canSync:!0},{key:"samplers",serverKey:"samplers",type:"string",canSync:!0}];class x{static roundFloatingPoint(e){return b(e)}static extractServerDefaults(e){if(!e)return{};const t={};for(const r of q)if(r.canSync&&r.serverKey in e){const s=e[r.serverKey];s!==void 0&&(t[r.key]=this.roundFloatingPoint(s))}return e.samplers&&Array.isArray(e.samplers)&&(t.samplers=e.samplers.join(";")),t}static mergeWithServerDefaults(e,t,r=new Set){const s={...e};for(const[o,i]of Object.entries(t))r.has(o)||(s[o]=this.roundFloatingPoint(i));return s}static getParameterInfo(e,t,r,s){const o=r[e]!==void 0,i=s.has(e);return{value:t,source:i?"custom":"default",serverDefault:o?r[e]:void 0,userOverride:i?t:void 0}}static canSyncParameter(e){return q.some(t=>t.key===e&&t.canSync)}static getSyncableParameterKeys(){return q.filter(e=>e.canSync).map(e=>e.key)}static validateServerParameter(e,t){const r=q.find(s=>s.key===e);if(!r)return!1;switch(r.type){case"number":return typeof t=="number"&&!isNaN(t);case"string":return typeof t=="string";case"boolean":return typeof t=="boolean";default:return!1}}static createParameterDiff(e,t){const r={};for(const s of this.getSyncableParameterKeys()){const o=e[s],i=t[s];i!==void 0&&(r[s]={current:o,server:i,differs:o!==i})}return r}}const re="DeltaWebui.selectedModel";class J{static async list(){const t=D().apiKey?.toString().trim(),r=await fetch(`${te}/v1/models`,{headers:{...t?{Authorization:`Bearer ${t}`}:{}}});if(!r.ok)throw new Error(`Failed to fetch model list (status ${r.status})`);return r.json()}static async listAvailable(){const e=await fetch("http://localhost:8081/api/models/available",{method:"GET",headers:{"Content-Type":"application/json"}});if(!e.ok)throw new Error(`Failed to fetch available models (status ${e.status})`);const t=await e.json();return Array.isArray(t)?{models:t}:t}static async listInstalled(){const e=await fetch("http://localhost:8081/api/models/list",{method:"GET",headers:{"Content-Type":"application/json"}});if(!e.ok)throw new Error(`Failed to fetch installed models (status ${e.status})`);const t=await e.json();return Array.isArray(t)?{models:t}:t}static async download(e,t){const r=await fetch("http://localhost:8081/api/models/download",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({model:e})});if(!r.ok){const s=await r.json().catch(()=>({}));throw new Error(s.error?.message||`Failed to start download (status ${r.status})`)}return new Promise((s,o)=>{const i=async()=>{try{const n=await fetch(`http://localhost:8081/api/models/download/progress/${encodeURIComponent(e)}`);if(!n.ok){if(n.status===404)return;clearInterval(l),o(new Error(`Failed to get progress (status ${n.status})`));return}const a=await n.json();if(t){const u=a.progress??0,h=a.current_mb??0,g=a.total_mb??0;t(u,h,g)}a.complete&&(clearInterval(l),a.success?s({success:!0,message:"Model downloaded successfully"}):o(new Error(a.error||"Download failed")))}catch(n){console.warn("Progress poll error:",n)}};i();const l=setInterval(i,200);setTimeout(()=>{clearInterval(l),o(new Error("Download timeout"))},1800*1e3)})}static async remove(e){const t=await fetch(`http://localhost:8081/api/models/${encodeURIComponent(e)}`,{method:"DELETE",headers:{"Content-Type":"application/json"}});if(!t.ok){const r=await t.json().catch(()=>({}));throw new Error(r.error?.message||`Failed to remove model (status ${t.status})`)}return t.json()}static async use(e){const t=await fetch("http://localhost:8081/api/models/use",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({model:e})});if(!t.ok){const r=await t.json().catch(()=>({}));throw new Error(r.error?.message||`Failed to switch model (status ${t.status})`)}return t.json()}}function se(m,e){let t=e;return{get value(){return t},set value(r){t=r}}}class oe{_models=[];_loading=!1;_updating=!1;_error=null;_selectedModelId=null;_selectedModelName=null;_persistedSelection=se(re,null);constructor(){const e=this._persistedSelection.value;e&&(this._selectedModelId=e.id,this._selectedModelName=e.model)}get models(){return this._models}get loading(){return this._loading}get updating(){return this._updating}get error(){return this._error}get selectedModelId(){return this._selectedModelId}get selectedModelName(){return this._selectedModelName}get selectedModel(){return this._selectedModelId?this._models.find(e=>e.id===this._selectedModelId)??null:null}async fetch(e=!1){if(!this._loading&&!(this._models.length>0&&!e)){this._loading=!0,this._error=null;try{const[t,r]=await Promise.allSettled([J.list(),J.listInstalled().catch(()=>null)]),s=[];if(t.status==="fulfilled"){const n=t.value;s.push(...n.data.map((a,u)=>{const h=n.models?.[u],g=Array.isArray(h?.capabilities)?h?.capabilities:[],C=h?.name&&h.name.trim().length>0?h.name:a.id,w=this.toDisplayName(C);return{id:a.id,name:w,model:h?.model||a.id,description:h?.description,capabilities:g.filter(E=>!!E),details:h?.details,meta:a.meta??null}}))}const o=new Map;if(r.status==="fulfilled"&&r.value!==null){const n=r.value,a=Array.isArray(n)?n:n.models||[];if(!Array.isArray(a))throw console.error("Invalid response format from model API:",n),new Error("Invalid response format from model management API");for(const u of a){const h=u.name,g=u.display_name||this.toDisplayName(u.name);o.set(h,{id:h,name:g,model:u.name,description:u.description,capabilities:[],details:{size:u.size_str,quantization:u.quantization},meta:null})}}for(const n of s)o.set(n.id,n);const i=Array.from(o.values());i.sort((n,a)=>n.name.localeCompare(a.name)),this._models=i;const l=this.determineInitialSelection(i,s);this._selectedModelId=l.id,this._selectedModelName=l.model,this._persistedSelection.value=l.id&&l.model?{id:l.id,model:l.model}:null}catch(t){throw this._models=[],this._error=t instanceof Error?t.message:"Failed to load models",t}finally{this._loading=!1}}}async select(e){if(!e||this._updating||this._selectedModelId===e)return;const t=this._models.find(r=>r.id===e);if(!t)throw new Error("Selected model is not available");this._updating=!0,this._error=null;try{try{const r=await J.use(t.model),s=r.model_path||t.model;!s||s===t.model?(console.warn("Model path not available, using model name:",t.model),this._selectedModelId=t.id,this._selectedModelName=t.model,this._persistedSelection.value={id:t.id,model:t.model}):(this._selectedModelId=t.id,this._selectedModelName=s,this._persistedSelection.value={id:t.id,model:s},r.restart_success?(console.log("âœ“ Model switched successfully! Server restarted with:",t.name),setTimeout(async()=>{try{await this.fetch(!0)}catch(o){console.warn("Failed to refresh model list after restart:",o)}},3e3)):console.warn("Model selected but server restart failed:",r.message))}catch(r){throw console.warn("Failed to switch model:",r),this._selectedModelId=t.id,this._selectedModelName=t.model,this._persistedSelection.value={id:t.id,model:t.model},r}}finally{this._updating=!1}}toDisplayName(e){const r=e.split(/\\|\//).pop();return r&&r.trim().length>0?r:e}determineInitialSelection(e,t=[]){if(t.length>0){const s=t[0],o=e.find(i=>i.id===s.id||i.model===s.model||i.model===s.id||i.name.toLowerCase()===s.name.toLowerCase());return o?{id:o.id,model:o.model}:{id:s.id,model:s.model}}if(this._selectedModelId){const s=e.find(o=>o.id===this._selectedModelId);if(s)return{id:s.id,model:s.model}}const r=this._persistedSelection.value;if(r?.id){const s=e.find(o=>o.id===r.id);if(s)return{id:s.id,model:s.model}}return e.length>0?{id:e[0].id,model:e[0].model}:{id:null,model:null}}}const v=new oe,ge=()=>v.models,ye=()=>v.loading,ve=()=>v.updating,_e=()=>v.error,be=()=>v.selectedModelId,ne=()=>v.selectedModelName;v.fetch.bind(v);v.select.bind(v);class ie{callbacks=new Set;isStreamingActive=!1;lastKnownState=null;conversationStates=new Map;activeConversationId=null;startStreaming(){this.isStreamingActive=!0}stopStreaming(){this.isStreamingActive=!1}clearState(){this.lastKnownState=null;for(const e of this.callbacks)try{e(null)}catch(t){console.error("Error in clearState callback:",t)}}isStreaming(){return this.isStreamingActive}setActiveConversation(e){this.activeConversationId=e,this.notifyCallbacks()}updateConversationState(e,t){this.conversationStates.set(e,t),e===this.activeConversationId&&(this.lastKnownState=t,this.notifyCallbacks())}getConversationState(e){return this.conversationStates.get(e)||null}clearConversationState(e){this.conversationStates.delete(e),e===this.activeConversationId&&(this.lastKnownState=null,this.notifyCallbacks())}notifyCallbacks(){const e=this.activeConversationId?this.conversationStates.get(this.activeConversationId)||null:this.lastKnownState;for(const t of this.callbacks)try{t(e)}catch(r){console.error("Error in slots service callback:",r)}}fetchAndNotify(){console.warn("SlotsService.fetchAndNotify() is deprecated - use timing data from ChatService instead")}subscribe(e){return this.callbacks.add(e),this.lastKnownState&&e(this.lastKnownState),()=>{this.callbacks.delete(e)}}async updateFromTimingData(e,t){const r=await this.parseCompletionTimingData(e);if(r===null){console.warn("Failed to parse timing data - skipping update");return}t?this.updateConversationState(t,r):(this.lastKnownState=r,this.notifyCallbacks())}async getContextTotal(){if(this.lastKnownState&&this.lastKnownState.contextTotal>0)return this.lastKnownState.contextTotal;try{const t=D().apiKey?.toString().trim(),r=await fetch("./slots",{headers:{...t?{Authorization:`Bearer ${t}`}:{}}});if(r.ok){const s=await r.json();if(Array.isArray(s)&&s.length>0){const o=s[0];if(o.n_ctx&&o.n_ctx>0)return o.n_ctx}}}catch(e){console.warn("Failed to fetch context total from /slots:",e)}return 4096}async parseCompletionTimingData(e){const t=e.prompt_n||0,r=e.predicted_n||0,s=e.predicted_per_second||0,o=e.cache_n||0,i=e.prompt_progress,l=await this.getContextTotal();if(l===null)return console.warn("No context total available - cannot calculate processing state"),null;const n=D(),a=n.max_tokens||-1,u=t+o+r,h=r,g=i?Math.round(i.processed/i.total*100):void 0;return{status:r>0?"generating":i?"preparing":"idle",tokensDecoded:r,tokensRemaining:a-r,contextUsed:u,contextTotal:l,outputTokensUsed:h,outputTokensMax:a,hasNextToken:r>0,tokensPerSecond:s,temperature:n.temperature??.8,topP:n.top_p??.95,speculative:!1,progressPercent:g,promptTokens:t,cacheTokens:o}}async getCurrentState(){if(this.activeConversationId){const e=this.conversationStates.get(this.activeConversationId);if(e)return e}if(this.lastKnownState)return this.lastKnownState;try{const{chatStore:e}=await import("./chat.svelte.js").then(r=>r.B),t=e.activeMessages;for(let r=t.length-1;r>=0;r--){const s=t[r];if(s.role==="assistant"&&s.timings){const o=await this.parseCompletionTimingData({prompt_n:s.timings.prompt_n||0,predicted_n:s.timings.predicted_n||0,predicted_per_second:s.timings.predicted_n&&s.timings.predicted_ms?s.timings.predicted_n/s.timings.predicted_ms*1e3:0,cache_n:s.timings.cache_n||0});if(o)return this.lastKnownState=o,o}}}catch(e){console.warn("Failed to restore timing data from messages:",e)}return null}}const ae=new ie;class W{abortControllers=new Map;async sendMessage(e,t={},r){const{stream:s,onChunk:o,onComplete:i,onError:l,onReasoningChunk:n,onModel:a,onFirstValidChunk:u,temperature:h,max_tokens:g,dynatemp_range:C,dynatemp_exponent:w,top_k:E,top_p:N,min_p:K,xtc_probability:O,xtc_threshold:_,typ_p:k,repeat_last_n:U,repeat_penalty:R,presence_penalty:j,frequency_penalty:L,dry_multiplier:y,dry_base:A,dry_allowed_length:F,dry_penalty_last_n:P,samplers:M,custom:T,timings_per_token:G}=t,B=D(),V=r||"default";this.abortControllers.has(V)&&this.abortControllers.get(V)?.abort();const Y=new AbortController;this.abortControllers.set(V,Y);const ee=e.map(c=>{if("id"in c&&"convId"in c&&"timestamp"in c){const f=c;return W.convertMessageToChatServiceData(f)}else return c}).filter(c=>c.role==="system"?(typeof c.content=="string"?c.content:"").trim().length>0:!0),p={messages:this.injectSystemMessage(ee).map(c=>({role:c.role,content:c.content})),stream:s},H=!!B.modelSelectorEnabled,X=H?ne():null;if(H&&X&&(p.model=X),p.reasoning_format=B.disableReasoningFormat?"none":"auto",h!==void 0&&(p.temperature=h),g!==void 0&&(p.max_tokens=g!==null&&g!==0?g:-1),C!==void 0&&(p.dynatemp_range=C),w!==void 0&&(p.dynatemp_exponent=w),E!==void 0&&(p.top_k=E),N!==void 0&&(p.top_p=N),K!==void 0&&(p.min_p=K),O!==void 0&&(p.xtc_probability=O),_!==void 0&&(p.xtc_threshold=_),k!==void 0&&(p.typ_p=k),U!==void 0&&(p.repeat_last_n=U),R!==void 0&&(p.repeat_penalty=R),j!==void 0&&(p.presence_penalty=j),L!==void 0&&(p.frequency_penalty=L),y!==void 0&&(p.dry_multiplier=y),A!==void 0&&(p.dry_base=A),F!==void 0&&(p.dry_allowed_length=F),P!==void 0&&(p.dry_penalty_last_n=P),M!==void 0&&(p.samplers=typeof M=="string"?M.split(";").filter(c=>c.trim()):M),G!==void 0&&(p.timings_per_token=G),T)try{const c=typeof T=="string"?JSON.parse(T):T;Object.assign(p,c)}catch(c){console.warn("Failed to parse custom parameters:",c)}try{const c=B.apiKey?.toString().trim(),f=await fetch("./v1/chat/completions",{method:"POST",headers:{"Content-Type":"application/json",...c?{Authorization:`Bearer ${c}`}:{}},body:JSON.stringify(p),signal:Y.signal});if(!f.ok){const Q=await this.parseErrorResponse(f);throw l&&l(Q),Q}if(s){await this.handleStreamResponse(f,o,i,l,n,a,u,r,Y.signal);return}else return this.handleNonStreamResponse(f,i,l,a)}catch(c){if(c instanceof Error&&c.name==="AbortError"){console.log("Chat completion request was aborted");return}let f;throw c instanceof Error?c.name==="TypeError"&&c.message.includes("fetch")?(f=new Error("Unable to connect to server - please check if the server is running"),f.name="NetworkError"):c.message.includes("ECONNREFUSED")?(f=new Error("Connection refused - server may be offline"),f.name="NetworkError"):c.message.includes("ETIMEDOUT")?(f=new Error("Request timed out - the server took too long to respond"),f.name="TimeoutError"):f=c:f=new Error("Unknown error occurred while sending message"),console.error("Error in sendMessage:",c),l&&l(f),f}finally{this.abortControllers.delete(V)}}async handleStreamResponse(e,t,r,s,o,i,l,n,a){const u=e.body?.getReader();if(!u)throw new Error("No response body");const h=new TextDecoder;let g="",C="",w=!1,E,N=!1,K=!1,O=!1;try{let _="";for(;!a?.aborted;){const{done:k,value:U}=await u.read();if(k||a?.aborted)break;_+=h.decode(U,{stream:!0});const R=_.split(`
`);_=R.pop()||"";for(const j of R){if(a?.aborted)break;if(j.startsWith("data: ")){const L=j.slice(6);if(L==="[DONE]"){N=!0;continue}try{const y=JSON.parse(L);!O&&y.object==="chat.completion.chunk"&&(O=!0,a?.aborted||l?.());const A=y.choices[0]?.delta?.content,F=y.choices[0]?.delta?.reasoning_content,P=y.timings,M=y.prompt_progress,T=this.extractModelName(y);T&&!K&&(K=!0,i?.(T)),(P||M)&&(this.updateProcessingState(P,M,n),P&&(E=P)),A&&(w=!0,g+=A,a?.aborted||t?.(A)),F&&(w=!0,C+=F,a?.aborted||o?.(F))}catch(y){console.error("Error parsing JSON chunk:",y)}}}if(a?.aborted)break}if(a?.aborted)return;if(N){if(!w&&g.length===0)throw new Error("No response received from server. Please try again.");r?.(g,C||void 0,E)}}catch(_){const k=_ instanceof Error?_:new Error("Stream error");throw s?.(k),k}finally{u.releaseLock()}}async handleNonStreamResponse(e,t,r,s){try{const o=await e.text();if(!o.trim())throw new Error("No response received from server. Please try again.");const i=JSON.parse(o),l=this.extractModelName(i);l&&s?.(l);const n=i.choices[0]?.message?.content||"",a=i.choices[0]?.message?.reasoning_content;if(a&&console.log("Full reasoning content:",a),!n.trim())throw new Error("No response received from server. Please try again.");return t?.(n,a),n}catch(o){const i=o instanceof Error?o:new Error("Parse error");throw r?.(i),i}}static convertMessageToChatServiceData(e){if(!e.extra||e.extra.length===0)return{role:e.role,content:e.content};const t=[];e.content&&t.push({type:"text",text:e.content});const r=e.extra.filter(n=>n.type==="imageFile");for(const n of r)t.push({type:"image_url",image_url:{url:n.base64Url}});const s=e.extra.filter(n=>n.type==="textFile");for(const n of s)t.push({type:"text",text:`

--- File: ${n.name} ---
${n.content}`});const o=e.extra.filter(n=>n.type==="context");for(const n of o)t.push({type:"text",text:`

--- File: ${n.name} ---
${n.content}`});const i=e.extra.filter(n=>n.type==="audioFile");for(const n of i)t.push({type:"input_audio",input_audio:{data:n.base64Data,format:n.mimeType.includes("wav")?"wav":"mp3"}});const l=e.extra.filter(n=>n.type==="pdfFile");for(const n of l)if(n.processedAsImages&&n.images)for(let a=0;a<n.images.length;a++)t.push({type:"image_url",image_url:{url:n.images[a]}});else t.push({type:"text",text:`

--- PDF File: ${n.name} ---
${n.content}`});return{role:e.role,content:t}}static async getServerProps(){try{const t=D().apiKey?.toString().trim(),r=await fetch("./props",{headers:{"Content-Type":"application/json",...t?{Authorization:`Bearer ${t}`}:{}}});if(!r.ok)throw new Error(`Failed to fetch server props: ${r.status}`);return await r.json()}catch(e){throw console.error("Error fetching server props:",e),e}}abort(e){if(e){const t=this.abortControllers.get(e);t&&(t.abort(),this.abortControllers.delete(e))}else{for(const t of this.abortControllers.values())t.abort();this.abortControllers.clear()}}injectSystemMessage(e){const r=D().systemMessage?.toString().trim();if(!r)return e;if(e.length>0&&e[0].role==="system"){if(e[0].content!==r){const o=[...e];return o[0]={role:"system",content:r},o}return e}return[{role:"system",content:r},...e]}async parseErrorResponse(e){try{const t=await e.text(),s=JSON.parse(t).error?.message||"Unknown server error",o=new Error(s);return o.name=e.status===400?"ServerError":"HttpError",o}catch{const t=new Error(`Server error (${e.status}): ${e.statusText}`);return t.name="HttpError",t}}extractModelName(e){const t=a=>typeof a=="object"&&a!==null?a:void 0,r=a=>typeof a=="string"&&a.trim()?a.trim():void 0,s=t(e);if(!s)return;const o=r(s.model);if(o)return o;const i=Array.isArray(s.choices)?t(s.choices[0]):void 0;if(!i)return;const l=r(t(i.delta)?.model);if(l)return l;const n=r(t(i.message)?.model);if(n)return n}updateProcessingState(e,t,r){const s=e?.predicted_ms&&e?.predicted_n?e.predicted_n/e.predicted_ms*1e3:0;ae.updateFromTimingData({prompt_n:e?.prompt_n||0,predicted_n:e?.predicted_n||0,predicted_per_second:s,cache_n:e?.cache_n||0,prompt_progress:t},r).catch(o=>{console.warn("Failed to update processing state:",o)})}}const Se=new W;class le{constructor(){}_serverProps=null;_loading=!1;_error=null;_serverWarning=null;_slotsEndpointAvailable=null;fetchServerPropsPromise=null;readCachedServerProps(){return null}persistServerProps(e){}get serverProps(){return this._serverProps}get loading(){return this._loading}get error(){return this._error}get serverWarning(){return this._serverWarning}get modelName(){return this._serverProps?.model_alias?this._serverProps.model_alias:this._serverProps?.model_path&&this._serverProps.model_path.split(/(\\|\/)/).pop()||null}get supportedModalities(){const e=[];return this._serverProps?.modalities?.audio&&e.push("audio"),this._serverProps?.modalities?.vision&&e.push("vision"),e}get supportsVision(){return this._serverProps?.modalities?.vision??!1}get supportsAudio(){return this._serverProps?.modalities?.audio??!1}get slotsEndpointAvailable(){return this._slotsEndpointAvailable}get serverDefaultParams(){return this._serverProps?.default_generation_settings?.params||null}async checkSlotsEndpointAvailability(){if(!this._serverProps){this._slotsEndpointAvailable=!1;return}if(this._serverProps.total_slots<=0){this._slotsEndpointAvailable=!1;return}try{const t=D().apiKey?.toString().trim();if((await fetch("./slots",{headers:{...t?{Authorization:`Bearer ${t}`}:{}}})).status===501){console.info("Slots endpoint not implemented - server started without --slots flag"),this._slotsEndpointAvailable=!1;return}this._slotsEndpointAvailable=!0}catch(e){console.warn("Unable to test slots endpoint availability:",e),this._slotsEndpointAvailable=!1}}async fetchServerProps(e={}){const{silent:t=!1}=e,r=t&&this._serverProps!==null;if(this.fetchServerPropsPromise)return this.fetchServerPropsPromise;r||(this._loading=!0,this._error=null,this._serverWarning=null);const s=this._serverProps!==null,o=(async()=>{try{const i=await W.getServerProps();this._serverProps=i,this.persistServerProps(i),this._error=null,this._serverWarning=null,await this.checkSlotsEndpointAvailability()}catch(i){if(r&&s){console.warn("Silent server props refresh failed, keeping cached data:",i);return}this.handleFetchServerPropsError(i,s)}finally{r||(this._loading=!1),this.fetchServerPropsPromise=null}})();this.fetchServerPropsPromise=o,await o}handleFetchServerPropsError(e,t){const{errorMessage:r,isOfflineLikeError:s,isServerSideError:o}=this.normalizeFetchError(e);let i=null;t?(this._error=null,(s||o)&&(this._serverWarning=r),console.warn("Failed to refresh server properties, continuing with cached values:",r)):(i=this.readCachedServerProps(),i?(this._serverProps=i,this._error=null,(s||o)&&(this._serverWarning=r),console.warn("Failed to refresh server properties, using cached values from localStorage:",r)):this._error=r),console.error("Error fetching server properties:",e)}normalizeFetchError(e){let t="Failed to connect to server",r=!1,s=!1;if(e instanceof Error){const o=e.message||"";e.name==="TypeError"&&o.includes("fetch")?(t="Server is not running or unreachable",r=!0):o.includes("ECONNREFUSED")?(t="Connection refused - server may be offline",r=!0):o.includes("ENOTFOUND")?(t="Server not found - check server address",r=!0):o.includes("ETIMEDOUT")?(t="Request timed out - the server took too long to respond",r=!0):o.includes("503")?(t="Server temporarily unavailable - try again shortly",s=!0):o.includes("500")?(t="Server error - check server logs",s=!0):o.includes("404")?t="Server endpoint not found":(o.includes("403")||o.includes("401"))&&(t="Access denied")}return{errorMessage:t,isOfflineLikeError:r,isServerSideError:s}}clear(){this._serverProps=null,this._error=null,this._serverWarning=null,this._loading=!1,this._slotsEndpointAvailable=null,this.fetchServerPropsPromise=null,this.persistServerProps(null)}}const S=new le,we=()=>S.serverProps,ke=()=>S.loading,Ce=()=>S.error,Ee=()=>S.serverWarning,Pe=()=>S.modelName,Me=()=>S.supportsVision,Te=()=>S.supportsAudio;function z(m,e,t){e in m&&(m[e]=t)}function $(m,e){return m[e]}function ce(m,e){const t={};for(const r of e){const s=$(m,r);s!==void 0&&(t[r]=s)}return t}class de{config={...I};theme="auto";isInitialized=!1;userOverrides=new Set;getServerDefaults(){const e=S.serverDefaultParams;return e?x.extractServerDefaults(e):{}}constructor(){}initialize(){try{this.loadConfig(),this.loadTheme(),this.isInitialized=!0}catch(e){console.error("Failed to initialize settings store:",e)}}loadConfig(){}loadTheme(){}updateConfig(e,t){if(this.config[e]=t,x.canSyncParameter(e)){const s=this.getServerDefaults()[e];if(s!==void 0){const o=b(t),i=b(s);o===i?this.userOverrides.delete(e):this.userOverrides.add(e)}}this.saveConfig()}updateMultipleConfig(e){Object.assign(this.config,e);const t=this.getServerDefaults();for(const[r,s]of Object.entries(e))if(x.canSyncParameter(r)){const o=t[r];if(o!==void 0){const i=b(s),l=b(o);i===l?this.userOverrides.delete(r):this.userOverrides.add(r)}}this.saveConfig()}saveConfig(){}updateTheme(e){this.theme=e,this.saveTheme()}saveTheme(){}resetConfig(){this.config={...I},this.saveConfig()}resetTheme(){this.theme="auto",this.saveTheme()}resetAll(){this.resetConfig(),this.resetTheme()}getConfig(e){return this.config[e]}getAllConfig(){return{...this.config}}syncWithServerDefaults(){if(!S.serverDefaultParams){console.warn("No server parameters available for initialization");return}const t=this.getServerDefaults();for(const[r,s]of Object.entries(t)){const o=$(this.config,r),i=b(o),l=b(s);i===l?(this.userOverrides.delete(r),z(this.config,r,s)):this.userOverrides.has(r)||z(this.config,r,s)}this.saveConfig(),console.log("Settings initialized with props defaults:",t),console.log("Current user overrides after sync:",Array.from(this.userOverrides))}clearAllUserOverrides(){this.userOverrides.clear(),this.saveConfig(),console.log("Cleared all user overrides")}forceSyncWithServerDefaults(){const e=this.getServerDefaults(),t=x.getSyncableParameterKeys();for(const r of t){if(e[r]!==void 0){const s=b(e[r]);z(this.config,r,s)}else if(r in I){const s=$(I,r);z(this.config,r,s)}this.userOverrides.delete(r)}this.saveConfig()}getParameterInfo(e){const t=this.getServerDefaults(),r=$(this.config,e);return x.getParameterInfo(e,r??"",t,this.userOverrides)}resetParameterToServerDefault(e){const t=this.getServerDefaults();if(t[e]!==void 0){const r=b(t[e]);this.config[e]=r}else if(e in I){const r=$(I,e);z(this.config,e,r)}this.userOverrides.delete(e),this.saveConfig()}getParameterDiff(){const e=this.getServerDefaults();if(Object.keys(e).length===0)return{};const t=ce(this.config,x.getSyncableParameterKeys());return x.createParameterDiff(t,e)}}const d=new de,D=()=>d.config,xe=d.updateConfig.bind(d),De=d.updateMultipleConfig.bind(d);d.updateTheme.bind(d);d.resetConfig.bind(d);d.resetTheme.bind(d);d.resetAll.bind(d);d.getConfig.bind(d);d.getAllConfig.bind(d);d.syncWithServerDefaults.bind(d);const Ae=d.forceSyncWithServerDefaults.bind(d),Fe=d.getParameterInfo.bind(d);d.resetParameterToServerDefault.bind(d);d.getParameterDiff.bind(d);d.clearAllUserOverrides.bind(d);export{J as M,x as P,I as S,Te as a,ye as b,D as c,ve as d,_e as e,be as f,ae as g,Pe as h,ke as i,d as j,Ee as k,S as l,ge as m,Ae as n,me as o,Fe as p,Ce as q,we as r,Me as s,xe as t,De as u,Se as v};
